# Open-source LLMs: Uncensored & secure AI locally with RAG

This comprehensive course focuses on empowering learners with the knowledge and skills to utilize open-source Large Language Models (LLMs) effectively, guiding them from initial setup and foundational concepts to building advanced AI applications. Key areas include local LLM deployment (using LM Studio, Ollama), in-depth prompt engineering, implementing Retrieval Augmented Generation (RAG) with vector databases (AnythingLLM, LlamaIndex), developing AI agents (LangChain, Flowise), and custom model fine-tuning, all while considering hardware needs, data privacy, and security.

[Enroll in the course on Udemy](https://www.udemy.com/course/open-source-llms-uncensored-secure-ai-locally-with-rag/)

## Table of Contents

- [Open-source LLMs: Uncensored \& secure AI locally with RAG](#open-source-llms-uncensored--secure-ai-locally-with-rag)
  - [Table of Contents](#table-of-contents)
  - [Week 1 - Introduction to Open-Source LLMs and Course Overview](#week-1---introduction-to-open-source-llms-and-course-overview)
    - [Day 1: Introduction and Overview](#day-1-introduction-and-overview)
    - [Day 2:  Why Open-Source LLMs? Differences, Advantages, and Disadvantages](#day-2--why-open-source-llms-differences-advantages-and-disadvantages)
    - [Day 3: The Easiest Way to Run Open-Source LLMs Locally \& What You Need](#day-3-the-easiest-way-to-run-open-source-llms-locally--what-you-need)
    - [Day 4: Prompt Engineering for Open-Source LLMs and Their Use in the Cloud](#day-4-prompt-engineering-for-open-source-llms-and-their-use-in-the-cloud)
    - [Day 5: Function Calling, RAG, and Vector Databases with Open-Source LLMs](#day-5-function-calling-rag-and-vector-databases-with-open-source-llms)
    - [Day 6:Optimizing RAG Apps: Tips for Data Preparation](#day-6optimizing-rag-apps-tips-for-data-preparation)
    - [Day 7: Local AI Agents with Open-Source LLMs](#day-7-local-ai-agents-with-open-source-llms)
    - [Day 8: Finetuning, Renting GPUs, Open-Source TTS, Finding the BEST LLM \& More Tips](#day-8-finetuning-renting-gpus-open-source-tts-finding-the-best-llm--more-tips)
    - [Day 9: Data Privacy, Security, and What Comes Next?](#day-9-data-privacy-security-and-what-comes-next)

## Week 1 - Introduction to Open-Source LLMs and Course Overview

### Day 1: Introduction and Overview

**What I did today:**

- Introduced the course, focusing on utilizing open-source LLMs for local and secure AI applications.
- Learned about key course areas: local LLM deployment (LM Studio, Ollama), prompt engineering, Retrieval Augmented Generation (RAG) with vector databases (AnythingLLM, LlamaIndex), AI agent development (LangChain, Flowise), and custom model fine-tuning.
- Understood the emphasis on hardware needs, data privacy, and security when working with local LLMs.
- Discussed the course's goal to transform learners into proficient users of LLMs, from basics to advanced topics like AI agents and local model operation.
- Explored the concept of uncensored LLMs (e.g., "Dolphin" fine-tunes) to understand model alignment, bias, and their implications, while prioritizing data privacy.
- Received tips for learning, such as adjusting video playback speed for optimal focus.
- Reviewed a comprehensive list of important links for open-source LLMs, installation tools, RAG resources, AI agents, and more, as detailed in the notebook.

**Resources**:

- [day1.ipynb](./notes/day1.ipynb)

### Day 2:  Why Open-Source LLMs? Differences, Advantages, and Disadvantages

**What I did today:**

- Gained a foundational understanding of Large Language Models (LLMs), including their core architecture (parameter and run files), three-phase training process (pre-training, fine-tuning, RLHF), and the significance of tokenization and context windows.
- Explored methods for discovering and evaluating LLMs, including familiarization with resources like the LMSys Chatbot Arena and Open LLM Leaderboards, and understood how to leverage them for model selection based on human preference and objective benchmarks.
- Critically analyzed the trade-offs between closed-source and open-source LLMs, identifying key disadvantages of closed-source models such as privacy risks, costs, limited customization, vendor lock-in, and the potential for bias and censorship.
- Recognized the substantial advantages of open-source LLMs, particularly focusing on enhanced data privacy through local deployment, cost-effectiveness, full customization capabilities, offline functionality, and freedom from externally imposed biases or restrictions.
- Investigated the capabilities of the newly released open-source model, DeepSeek-R1, noting its reported high performance in reasoning tasks due to "Test-Time Compute" and its permissive MIT license for commercial use, including the availability of distilled versions and a testing API.
- Applied conceptual knowledge by analyzing practical scenarios, such as selecting appropriate LLM types for tasks involving sensitive data, explaining technical concepts to non-technical audiences, and strategizing the validation of LLM-generated code.
- Developed a deeper appreciation for the practical implications of LLM attributes by considering how to leverage specific model features (e.g., DeepSeek-R1's reasoning) for advanced applications like generating reliable unit tests.
- Solidified understanding of how to make informed LLM selections by applying learned principles to choose models for specialized tasks, such as using open-source models for projects requiring domain-specific customization and freedom from content restrictions, like historical text analysis.
- Prepared for practical application by understanding the importance of local LLM deployment for privacy and control, setting the stage for hands-on experience with running open-source models.
- Embraced an action-oriented definition of learning, committing to apply this knowledge to make demonstrably different and more informed LLM choices in future projects, particularly advocating for open-source solutions where data privacy and transparency are paramount.

**Resources**:

- [day2.ipynb](./notes/day2.ipynb)

### Day 3: The Easiest Way to Run Open-Source LLMs Locally & What You Need

### Day 4: Prompt Engineering for Open-Source LLMs and Their Use in the Cloud

### Day 5: Function Calling, RAG, and Vector Databases with Open-Source LLMs

### Day 6:Optimizing RAG Apps: Tips for Data Preparation

### Day 7: Local AI Agents with Open-Source LLMs

### Day 8: Finetuning, Renting GPUs, Open-Source TTS, Finding the BEST LLM & More Tips

### Day 9: Data Privacy, Security, and What Comes Next?
